import express from "express";
import OpenAI from "openai";

const app = express();
app.use(express.json());

// =====================
// ENV
// =====================
const PORT = Number(process.env.PORT || 8080);
const BOT_NAME = (process.env.BOT_NAME || "QualiConsult AI").trim();

const TELEGRAM_BOT_TOKEN = (process.env.TELEGRAM_BOT_TOKEN || "").trim();
const OPENAI_API_KEY = (process.env.OPENAI_API_KEY || "").trim();
const OPENAI_MODEL = (process.env.OPENAI_MODEL || "gpt-4.1-mini").trim();

const TG_API = TELEGRAM_BOT_TOKEN ? `https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}` : "";

const mask = (s) => (s ? `${s.slice(0, 4)}...${s.slice(-4)} (len=${s.length})` : "(missing)");
console.log("=== STARTUP ENV CHECK ===");
console.log("PORT:", PORT);
console.log("BOT_NAME:", BOT_NAME);
console.log("TELEGRAM_BOT_TOKEN:", TELEGRAM_BOT_TOKEN ? "OK" : "MISSING");
console.log("OPENAI_API_KEY:", mask(OPENAI_API_KEY));
console.log("OPENAI_MODEL:", OPENAI_MODEL);
console.log("=========================");

// =====================
// OpenAI client
// =====================
const openai = OPENAI_API_KEY ? new OpenAI({ apiKey: OPENAI_API_KEY }) : null;

// =====================
// Telegram helpers
// =====================
const TG_LIMIT = 3800; // keep margin

function splitTelegram(text) {
  const s = (text || "").trim();
  if (!s) return [];
  if (s.length <= TG_LIMIT) return [s];

  const parts = [];
  let chunk = "";
  for (const line of s.split("\n")) {
    if ((chunk + "\n" + line).length > TG_LIMIT) {
      parts.push(chunk.trim());
      chunk = line;
    } else {
      chunk += (chunk ? "\n" : "") + line;
    }
  }
  if (chunk.trim()) parts.push(chunk.trim());
  return parts;
}

async function tgSend(chatId, text) {
  if (!TG_API) return false;
  const resp = await fetch(`${TG_API}/sendMessage`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ chat_id: chatId, text }),
  });
  const body = await resp.text();
  console.log("๐ค Telegram send:", resp.status, body);
  return resp.ok;
}

async function tgSendMany(chatId, text) {
  const parts = splitTelegram(text);
  for (const p of parts) {
    await tgSend(chatId, p);
  }
}

// =====================
// RAM Sessions (TEMP)
// =====================
// NOTE: This is NOT database memory. It is in-memory only, for better dialogue flow.
// TTL: 30 minutes
const SESSIONS = new Map();
const SESSION_TTL_MS = 30 * 60 * 1000;

function now() {
  return Date.now();
}

function getSession(chatId) {
  const key = String(chatId);
  const s = SESSIONS.get(key);
  if (!s) return null;
  if (now() - s.updated_at > SESSION_TTL_MS) {
    SESSIONS.delete(key);
    return null;
  }
  return s;
}

function setSession(chatId, patch) {
  const key = String(chatId);
  const old = SESSIONS.get(key) || {};
  SESSIONS.set(key, { ...old, ...patch, updated_at: now() });
}

function resetSession(chatId) {
  SESSIONS.delete(String(chatId));
}

// =====================
// Bot Personality
// =====================
function systemPrompt() {
  return `
ุฃูุช "QualiConsult AI" ูุณุชุดุงุฑ ุชููู ูุชุฎุตุต ูู:
- ุงูุฌูุฏุฉ (QMS / ISO 9001)
- ุณูุงูุฉ ุงูุบุฐุงุก (FSMS / HACCP / ISO 22000 / GMP)
- ุงูุตุญุฉ ูุงูุณูุงูุฉ ุงูููููุฉ (OHS) ุนูุฏ ุงูุญุงุฌุฉ
- ุงูุชููุฒ ุงููุคุณุณู
- KPI/BSC/OKR
- Lean / RCA / CAPA

ููุงุนุฏ ุงูุฑุฏ:
1) ุนููู ูุจุงุดุฑุ ุจุฏูู ุญุดู ูุจุฏูู ุชูุฑุงุฑ ุงูุชุญูุฉ ูู ูุฑุฉ.
2) ุงุจุฏุฃ ุจุชุดุฎูุต ุณุฑูุน (ุณุทุฑูู) ุซู ุฎุทูุงุช ุชูููุฐูุฉ ูุงุจูุฉ ููุชุทุจูู.
3) ุฅุฐุง ุงูุณุคุงู ูุงูุต: ุงุณุฃู ุณุคุงู ูุงุญุฏ "ุญุงุณู" ููุทุ ุซู ุงูุชุฑุญ ุงูุชุฑุงุถูุง ูุนููููุง ุฅุฐุง ูู ูุฑุฏ ุงููุณุชุฎุฏู.
4) ุนูุฏ ุทูุจ (checklist / form / template / report): ูุฏู ูููุฐุฌ ุฌุงูุฒ ูููุณุฎ + ุญููู ูุงุถุญุฉ.
5) ูุง ุชููู ุงูุฑุฏ ุจุณุคุงู ุนุงู ูุซู: "ููู ุฃุณุงุนุฏูุ" โ ููุท ุงุณุฃู ุณุคุงู ูุชุงุจุนุฉ ูุญุฏุฏ ุนูุฏ ุงูุถุฑูุฑุฉ.
6) ุงููุบุฉ: ุงูุนุฑุจูุฉ ุงููุจุณุทุฉุ ูุงุณุชุฎุฏู ูุตุทูุญ ุฅูุฌููุฒู ุจูู ููุณูู ุนูุฏ ุงูุญุงุฌุฉ.
  `.trim();
}

function helpText() {
  return (
    `ูุฑุญุจุงู ๐ ุฃูุง ${BOT_NAME}.\n\n` +
    `ุงูุชุจ ุณุคุงูู ูุจุงุดุฑุฉ ูู:\n` +
    `โข ุงูุฌูุฏุฉ\nโข ุณูุงูุฉ ุงูุบุฐุงุก\nโข HACCP\nโข KPI\nโข ุงูุชููุฒ ุงููุคุณุณู\nโข Lean\n\n` +
    `ุฃูุงูุฑ ูููุฏุฉ:\n` +
    `/help โ ุงููุณุงุนุฏุฉ\n` +
    `/reset โ ุชุตููุฑ ุณูุงู ุงููุญุงุฏุซุฉ\n\n` +
    `ุฃูุซูุฉ:\n` +
    `- ููู ุฃุทุจู HACCP ูู ูุฎุจุฒ ุตุบูุฑุ\n` +
    `- ุงุนูู ูู checklist ูุฑุงุฌุนุฉ ุฏุงุฎููุฉ ููุณู ุงูุฌูุฏุฉ ูู ูุฎุจุฒ\n` +
    `- ุงุจูู KPI dashboard outline ููุณู ุงูุฌูุฏุฉ\n`
  );
}

// =====================
// Follow-up logic (NO need to type "ุฃููู")
// =====================
function normalizeYesNo(t) {
  const x = (t || "").trim().toLowerCase();
  const yes = ["ูุนู", "ุงููู", "ุฃููุง", "ุชูุงู", "ok", "yes", "ููุงูู", "ูุงูู", "ุตุญ", "ุฃููุฏ", "ุชูุงูู"];
  const no = ["ูุง", "no", "ุบูุฑ", "ูู", "ูุด", "ูุง", "ุงุจุฏุงู", "ุฑูุถ", "ูุงุง"];
  if (yes.includes(x)) return "yes";
  if (no.includes(x)) return "no";
  return null;
}

function isContinue(t) {
  const x = (t || "").trim().toLowerCase();
  const cont = [
    "ุงููู", "ุฃููู", "ููู", "ูููู", "ุชุงุจุน", "ูุงุตู",
    "continue", "go on", "more", "ุฒูุฏ", "ุฒูุฏูู",
    "ููู ูู ููุง", "ููู ูู ุขุฎุฑ ููุทุฉ", "continue from last"
  ];
  return cont.includes(x);
}

function isShortFollowup(text) {
  const t = (text || "").trim();
  if (!t) return false;
  // short confirmations / nudges that should continue context
  // examples: "ุชูุงู", "ุงููู", "ูููุณ", "ุชูุงู ุฌุฏุง", "ุญูู", "ุฒูุฏ", "ุทูุจ"
  return t.length <= 12;
}

// =====================
// AI Core
// =====================
async function askAI(chatId, userText) {
  if (!openai) return "โ OPENAI_API_KEY ุบูุฑ ููุฌูุฏ ูู ูุชุบูุฑุงุช Railway.";

  const session = getSession(chatId);

  const yn = normalizeYesNo(userText);
  const cont = isContinue(userText);

  let stitchedUserText = userText;

  // 1) If user explicitly says continue -> continue from last reply
  if (cont && session?.last_reply) {
    stitchedUserText =
      `ุฃููู ูู ุญูุซ ุชูููุช ูู ุงูุฑุฏ ุงูุณุงุจู ุจุฏูู ุฅุนุงุฏุฉ ูุง ููู.\n` +
      `ุงูุฑุฏ ุงูุณุงุจู:\n${session.last_reply}\n\n` +
      `ุฃููู ุงูุขู ุจุชูุงุตูู ุนูููุฉ ุฅุถุงููุฉ (ุฎุทูุงุช + ุฃูุซูุฉ + ููุงุฐุฌ ูุฎุชุตุฑุฉ ุนูุฏ ุงูุญุงุฌุฉ).`;
  }

  // 2) If user answered yes/no and we had a followup question -> bind it
  if (!cont && yn && session?.last_followup_question) {
    stitchedUserText =
      `ุณุคุงู ุงููุชุงุจุนุฉ ุงูุณุงุจู ูุงู: "${session.last_followup_question}"\n` +
      `ุฅุฌุงุจุชู ุนููู ุงูุขู ูู: "${userText}"\n` +
      `ุงูุขู ุฃููู ุงูุญู ุจูุงุกู ุนูู ูุฐู ุงูุฅุฌุงุจุฉ ูุจุงุดุฑุฉุ ุจุฏูู ุฅุนุงุฏุฉ ุงูุฃุณุฆูุฉ ุงููุฏููุฉ ุฃู ุงูุชุญูุฉ.`;
  }

  // 3) If user wrote a short message and we have context -> treat it as continue
  if (!cont && !yn && session?.last_reply && isShortFollowup(userText)) {
    stitchedUserText =
      `ุงุนุชุจุฑ ูุฐู ุงูุฑุณุงูุฉ ูุชุงุจุนุฉ ููุณูุงู ุงูุณุงุจู.\n` +
      `ุงูุณูุงู ุงูุณุงุจู:\n${session.last_reply}\n\n` +
      `ุชุงุจุน ุงูุขู ุจุดูู ุนููู ููุจุงุดุฑ ูุน ุฅุถุงูุฉ ููุงุท ุชูููุฐูุฉ ูููุงุฐุฌ ุฅุฐุง ูุงูุช ููุงุณุจุฉ.`;
  }

  // Lightweight context: last Q + last reply
  const context = [];
  if (session?.last_question && session?.last_reply) {
    context.push({
      role: "user",
      content: `ุงูุณูุงู ุงูุณุงุจู (ููุงุณุชูุฑุงุฑูุฉ ููุท): ุณุคุงูู ูุงู: ${session.last_question}`,
    });
    context.push({
      role: "assistant",
      content: `ููุงู ุฑุฏู: ${session.last_reply}`,
    });
  }

  try {
    const resp = await openai.responses.create({
      model: OPENAI_MODEL,
      max_output_tokens: 650, // more room to avoid cut-offs
      input: [
        { role: "system", content: systemPrompt() },
        ...context,
        { role: "user", content: stitchedUserText },
      ],
    });

    const out = (resp.output_text || "").trim();
    const answer = out || "ูุง ูุฏุฑุช ุฃุทูุน ุฑุฏ ุงูุขู. ุฌุฑูุจ ุชุงูู.";

    // Heuristic: if last non-empty line ends with "ุ" treat as followup
    const lines = answer.split("\n").map((l) => l.trim()).filter(Boolean);
    const lastLine = lines[lines.length - 1] || "";
    const followup = lastLine.endsWith("ุ") ? lastLine : "";

    setSession(chatId, {
      last_question: userText,
      last_reply: answer,
      last_followup_question: followup || "",
    });

    return answer;
  } catch (err) {
    console.error("โ OpenAI error:", err?.status, err?.message || err);
    return "ุญุฏุซ ุฎุทุฃ ูู ูุญุฑู ุงูุฐูุงุก. ุฌุฑูุจ ุชุงูู.";
  }
}
app.use("/files", express.static("public/files"));

// =====================
// Routes
// =====================
app.get("/", (req, res) => res.send(`${BOT_NAME} running โ`));
app.get("/health", (req, res) => res.json({ ok: true }));

// Test AI from browser
app.get("/ai-test", async (req, res) => {
  const q = (req.query.q || "ุงุฎุชุจุงุฑ").toString();
  const ans = await askAI("test", q);
  res.json({ ok: true, model: OPENAI_MODEL, answer: ans });
});

// Telegram Webhook
app.post("/telegram/webhook", async (req, res) => {
  // respond fast
  res.sendStatus(200);

  try {
    console.log("๐ฉ Telegram update:", JSON.stringify(req.body));

    const msg = req.body?.message;
    const chatId = msg?.chat?.id;
    const text = msg?.text?.trim();

    if (!chatId || !text) return;

    // Commands
    if (text.startsWith("/")) {
      if (text === "/help" || text === "/start") {
        await tgSendMany(chatId, helpText());
        return;
      }
      if (text === "/reset") {
        resetSession(chatId);
        await tgSend(chatId, "ุชู ุชุตููุฑ ุณูุงู ุงููุญุงุฏุซุฉ โ\nุงูุชุจ ุณุคุงูู ูู ุฌุฏูุฏ.");
        return;
      }
      await tgSend(chatId, "ุฃูุฑ ุบูุฑ ูุนุฑูู. ุงุณุชุฎุฏู /help");
      return;
    }

    // Normal messages
    const answer = await askAI(chatId, text);
    await tgSendMany(chatId, answer);
  } catch (err) {
    console.error("โ Webhook error:", err);
    try {
      const chatId = req.body?.message?.chat?.id;
      if (chatId) await tgSend(chatId, "ุญุฏุซ ุฎุทุฃ ุนุงู. ุฌุฑูุจ ุชุงูู.");
    } catch {}
  }
});

app.listen(PORT, () => {
  console.log(`๐ Server running on port ${PORT}`);
  console.log("MODEL:", OPENAI_MODEL);
});
